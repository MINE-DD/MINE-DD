{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab959852-e492-42fc-af79-11a45ccf5ace",
   "metadata": {},
   "source": [
    "# RAG prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1467e843-eb28-42dc-88fc-adff47e6f475",
   "metadata": {},
   "source": [
    "This notebook builds a langgraph that showcases the potential of a RAG agent that summarises scientific evidence from the literature and extracts statistical significant associations between pathogens and enviromental factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a261e50-c86a-4c8d-9748-db883a4ed771",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23f28e0e-d670-4678-8f36-053bffe9b9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from os.path import exists\n",
    "import sqlite3\n",
    "# LLM\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema import Document, AIMessage\n",
    "# to chunk the text\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# to make/store embeddings \n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_community.embeddings.spacy_embeddings import SpacyEmbeddings\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "# to build/display/run a langgraph\n",
    "from langgraph.graph import StateGraph\n",
    "from IPython.display import Image, display\n",
    "import operator\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List, Annotated\n",
    "from langgraph.graph import END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3076fada-99f5-40f2-9fa7-6c5a23e27835",
   "metadata": {},
   "source": [
    "#### Set-up the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e3603ea-8c3f-47db-afb9-b5c9c0e45eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### llama 3.2-3b\n",
    "\n",
    "local_llm = \"llama3.2:3b-instruct-fp16\"\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "llm_json_mode = ChatOllama(model=local_llm, temperature=0, format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f28008-99e0-4429-b4fa-0f67ef243428",
   "metadata": {},
   "source": [
    "## Note: Skip to the embeddings part if you don't have the `db` file as the embeddings are run on the text contained in the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254da7c5-731a-4f26-be2a-e7ebe62ea3f1",
   "metadata": {},
   "source": [
    "#### Load database `db` of papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c77352d-51f2-4707-bea9-33ee88e28df1",
   "metadata": {},
   "source": [
    "This is the path of the `db` database containing the text extracted from the relevant papers with llamaParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9ecec23-da9b-4d14-80bb-b85136e8c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_path = 'literature_relevant.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea33170-e7b0-43eb-b04c-94c050b15dce",
   "metadata": {},
   "source": [
    "Define `extract_full_text_content` - this function below takes as input the SQL database and returns the full-text of the papers per page content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb5a67ef-4eef-45f8-887b-3b2314596bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_full_text_content(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # get list of tables in the database\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "\n",
    "    text_content = []\n",
    "\n",
    "    # get fulltext table content\n",
    "    table_name = 'literature_fulltext'\n",
    "\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "    columns = cursor.fetchall()\n",
    "    column_names = [col[1] for col in columns]\n",
    "    column_types = [col[2] for col in columns]\n",
    "\n",
    "    # Retrieve all rows/papers from the table\n",
    "    cursor.execute(f\"SELECT fulltext FROM {table_name};\")\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Iterate through the rows (which are papers) and extract text content\n",
    "    for row in rows:\n",
    "        row_text = []\n",
    "        for idx, value in enumerate(row):\n",
    "            if column_types[idx].lower() == 'text' and value is not None:\n",
    "                row_text.append(value)\n",
    "\n",
    "        if row_text:\n",
    "            text_content.extend(row_text)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return text_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0debe0fe-abb9-4fab-9a52-c86be7164ce7",
   "metadata": {},
   "source": [
    "Extract the content below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0815fb-8e72-4e05-89b9-1b4aa5b32544",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = database_path\n",
    "docs = extract_full_text_content(db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9972b1b8-6c88-4a9d-9de1-68d834eeb2e2",
   "metadata": {},
   "source": [
    "`docs` is a list containing the full text per paper. This is not directly usable for `langchain` and it must be converted into a `Document` istance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c41d1-b1fd-4212-b382-a28654a540db",
   "metadata": {},
   "source": [
    "We do this together with the splitting, by using the function `.create_documents` while splitting it, within the `RecursiveCharacterTextSplitter`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf10e28-d900-4183-9b40-1ce59dfd9756",
   "metadata": {},
   "source": [
    "#### Chunk text and extract embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca33d72-2295-497c-8068-2e6fcd28f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=5000, chunk_overlap=0\n",
    ")\n",
    "\n",
    "documents = text_splitter.create_documents([text for text in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "820f25ed-57cf-4e7b-85d3-526685e6fde5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Rotavirus Seasonality and Age Effects in a Birth Cohort Study of Southern India\n",
      "\n",
      "#\n",
      "# Rotavirus Seasonality and Age Effects in a Birth Cohort Study of Southern India\n",
      "\n",
      "Rajiv Sarkar1, Gagandeep Kang1, Elena N. Naumova1,2*\n",
      "\n",
      "1Department of Gastrointestinal Sciences, Christian Medical College, Vellore, TN, India\n",
      "\n",
      "2Department of Civil and Environmental Engineering, Tufts University School of Engineering, Boston, Massachusetts, United States of America\n",
      "\n",
      "# Abstract\n",
      "\n",
      "# Introduction\n",
      "\n",
      "Understanding the temporal patterns in disease occurrence is valuable for formulating effective disease preventive progr\n"
     ]
    }
   ],
   "source": [
    "# does this print something meaningful? must have .page_content() functionality\n",
    "print(documents[0].page_content[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f09669fa-c1b4-43b3-a837-2a7d013ca3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bbe93d7-6ab9-43d8-bf87-1a6016f19cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy Embeddings -- a bit faster than the nomic ones\n",
    "# we save the embeddings into a in-memory vector store from sklearn, that is SKLearnVectorStore\n",
    "persist_path = f\"embeddings/\"+\"union.bson\"\n",
    "\n",
    "def create_embeddings(out_path, docs):\n",
    "    folder = os.path.dirname(out_path)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    if exists(out_path):\n",
    "        \n",
    "        vectorstore = SKLearnVectorStore(\n",
    "            embedding=SpacyEmbeddings(model_name='en_core_web_sm'),\n",
    "            persist_path=out_path,\n",
    "            serializer=\"bson\") \n",
    "        print(\"Vector store was loaded from\", out_path)\n",
    "        \n",
    "    else:\n",
    "        vectorstore = SKLearnVectorStore.from_documents(\n",
    "            documents=docs,\n",
    "            embedding=SpacyEmbeddings(model_name='en_core_web_sm'),\n",
    "            persist_path=out_path,\n",
    "            serializer=\"bson\")\n",
    "        vectorstore.persist()\n",
    "        print(\"Vector store was persisted to\", out_path)\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb6f47a3-7379-4d1d-98ed-9ac7284f866a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store was persisted to embeddings/union.bson\n"
     ]
    }
   ],
   "source": [
    "vectorstore = create_embeddings(persist_path, docs=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7aee1b2c-7bc2-4132-8c2a-f14d22711f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bfe7df-e551-4415-8305-dcfe386163a3",
   "metadata": {},
   "source": [
    "You can check if the retriever works by asking to retrieve documents similar to your search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92fa4aff-ec64-4bac-8f91-ef37a5ccbf84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enviroment_docs = retriever.invoke(\"Escherichia coli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "057ef683-9a26-4c61-82be-84a25f9553a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Figure 5 shows the plot of the cumulative sums of actual and predicted values for the ZIP model. The validation analyses indicate that the model had reasonable accuracy over the predictive period (RMS'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enviroment_docs[0].page_content[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f176c2-362c-4f39-ba29-1e1bc72520bd",
   "metadata": {},
   "source": [
    "# build a langGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecad0635-9c43-478f-a77b-06222a91d67b",
   "metadata": {},
   "source": [
    "set up a state. A state is a schema that is going to survive across the steps above. All inputs/output across the prompting is going to survive across the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "981b57cd-f30e-47ed-94fc-9e0c46197643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the class state \n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Graph state is a dictionary that contains information we want to propagate to, and modify in, each graph node.\n",
    "    \"\"\"\n",
    "    question : str # User question\n",
    "    generation : str # LLM generation\n",
    "    max_retries : int # Max number of retries for answer generation \n",
    "    answers : int # Number of answers generated\n",
    "    loop_step: Annotated[int, operator.add] \n",
    "    documents : List[str] # List of retrieved documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2a9696-61ea-499d-b8cc-8e0c15f01c35",
   "metadata": {},
   "source": [
    "Take each of the steps above, and wrapping those into individual functions (which are nodes). They take state as input, and modify it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ba1a1-e2ea-45a8-97b2-f435dba67b38",
   "metadata": {},
   "source": [
    "Some of the functions are 'edges', so they basically evaluate the input and decide where to go (which nodes) next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db20b7a2-d13f-4d51-b8c4-0f45a53bb61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "### Nodes\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from vectorstore\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Write retrieved documents to documents key in state\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents}\n",
    "    \n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer using RAG on retrieved documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    loop_step = state.get(\"loop_step\", 0)\n",
    "    \n",
    "    rag_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "\n",
    "    Here is the context to use to answer the question:\n",
    "\n",
    "    {context} \n",
    "\n",
    "    Think carefully about the above context. \n",
    "\n",
    "    Now, review the user question:\n",
    "\n",
    "    {question}\n",
    "\n",
    "    Provide an answer to this questions using only the above context. \n",
    "\n",
    "    Use 10 sentences maximum and keep the answer concise.\n",
    "\n",
    "    Answer:\"\"\"\n",
    "    \n",
    "    \n",
    "    # RAG generation\n",
    "    docs_txt = format_docs(documents)\n",
    "    rag_prompt_formatted = rag_prompt.format(context=docs_txt, question=question)\n",
    "    generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "    return {\"generation\": generation, \"loop_step\": loop_step+1}\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "    If any document is not relevant, we will set a flag AND THAT'S IT\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    doc_grader_prompt = \"\"\"Here is the retrieved document: \\n\\n {document} \\n\\n Here is the user question: \\n\\n {question}. \n",
    "\n",
    "    This carefully and objectively assess whether the document contains at least some information that is relevant to the question.\n",
    "\n",
    "    Return JSON with single key, binary_score, that is 'yes' or 'no' score to indicate whether the document contains at least some information that is relevant to the question.\"\"\"\n",
    "    \n",
    "    doc_grader_instructions = \"\"\"You are a grader assessing relevance of a retrieved document to a user question.\n",
    "\n",
    "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\"\"\"\n",
    "    \n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\" \n",
    "    for d in documents:\n",
    "        doc_grader_prompt_formatted = doc_grader_prompt.format(document=d.page_content, question=question)\n",
    "        result = llm_json_mode.invoke([SystemMessage(content=doc_grader_instructions)] + [HumanMessage(content=doc_grader_prompt_formatted)])\n",
    "        grade = json.loads(result.content)['binary_score']\n",
    "        # Document relevant\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        # Document not relevant\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            # We do not include the document in filtered_docs\n",
    "            # We set a flag to indicate that we want to run web search\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"web_search\": web_search}\n",
    "    \n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "    max_retries = state.get(\"max_retries\", 3) # Default to 3 if not provided\n",
    "\n",
    "    hallucination_grader_prompt_formatted = hallucination_grader_prompt.format(documents=format_docs(documents), generation=generation.content)\n",
    "    result = llm_json_mode.invoke([SystemMessage(content=hallucination_grader_instructions)] + [HumanMessage(content=hallucination_grader_prompt_formatted)])\n",
    "    grade = json.loads(result.content)['binary_score']\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        # Test using question and generation from above \n",
    "        answer_grader_prompt_formatted = answer_grader_prompt.format(question=question, generation=generation.content)\n",
    "        result = llm_json_mode.invoke([SystemMessage(content=answer_grader_instructions)] + [HumanMessage(content=answer_grader_prompt_formatted)])\n",
    "        grade = json.loads(result.content)['binary_score']\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        elif state[\"loop_step\"] <= max_retries:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: MAX RETRIES REACHED---\")\n",
    "            return \"max retries\"  \n",
    "    elif state[\"loop_step\"] <= max_retries:\n",
    "        print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\"\n",
    "    else:\n",
    "        print(\"---DECISION: MAX RETRIES REACHED---\")\n",
    "        return \"max retries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34dc5277-9027-4388-a4af-9dbc200cca68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the StateGraph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generate\n",
    "\n",
    "# Build graph\n",
    "# Directly set \"retrieve\" as the entry point, skipping route_question and web_search\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "\n",
    "# Set edges to transition between nodes\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")  # After retrieving, grade documents\n",
    "workflow.add_edge(\"grade_documents\", \"generate\")  # After grading, generate the response\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3531ed5a-d6c6-41ea-a0a0-53775306b164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GENERATE---\n",
      "The study suggests that environmental factors, such as rainfall and temperature, do not play a significant role in the prevalence of Campylobacter infection. The degree of contamination is more important than the total poultry weight produced. Human infections are related to people returning from travel abroad and domestic use of antibiotics. Rainfall and latitude/longitude have no association with Campylobacter cases. Surface water/sewage exposure and population ageing/demographic change may contribute to disease epidemiology, but their impact is unclear. The economic situation and socioeconomic status also do not appear to be significant factors. Climate impacts are mentioned as a potential driver for change, but more research is needed to understand this relationship. The study highlights the need for further examination of transmission routes and underlying population factors. Environmental factors such as rainfall and temperature may have an indirect impact on disease prevalence through other means, but their direct role is unclear. Overall, the evidence suggests that environmental factors are not a primary driver of Campylobacter infection.\n"
     ]
    }
   ],
   "source": [
    "question = {\"question\": \"What is the role of enviromental factors in the prevalence of diarrheal pathogens?\", \n",
    "            \"max_retries\": 3}\n",
    "\n",
    "documents_list = []\n",
    "\n",
    "for event in graph.stream(question, stream_mode=\"values\"):\n",
    "    if \"generation\" in event and isinstance(event[\"generation\"], AIMessage):\n",
    "        # Print only the content of the AIMessage\n",
    "        print(event[\"generation\"].content)  \n",
    "    \n",
    "    # event contains documents (which are stored under the key 'documents')\n",
    "    if \"documents\" in event:\n",
    "        # append the documents to the documents_list, but do not print them\n",
    "        documents_list.extend(event[\"documents\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be98e668-e5ab-45e7-b9c4-2d32475acf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1249e1-aba6-4e5a-875c-28cf295ca363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_september",
   "language": "python",
   "name": "rag_september"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
