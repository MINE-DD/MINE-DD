{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416f0ceb",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentence-transformers\n",
    "# pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from minedd.document import DocumentPDF, DocumentMarkdown\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "PAPERS_DIR = Path.home() / \"papers_minedd\"\n",
    "\n",
    "test_paper = PAPERS_DIR / \"Seasonality of rotavirus disease in the tropics_ a systematic review and meta-analysis.pdf\"\n",
    "\n",
    "pdf_paper = DocumentPDF(pdf_path=str(test_paper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7219a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pdf_paper.get_grobid_chunks()\n",
    "if len(docs) > 0:\n",
    "    print(len(docs))\n",
    "    print(docs[0].metadata.keys())\n",
    "    print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca81bea",
   "metadata": {},
   "source": [
    "## PDF to Chunks\n",
    "\n",
    "### JSON Format = REQUIRES GROBID!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a744f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "docs = pdf_paper.get_grobid_chunks(return_as_dict=True, group_dict_by_section=True)\n",
    "with open(\"outputs/test_paper_grobid.json\", \"w\") as f:\n",
    "    json.dump(docs, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158aa2e",
   "metadata": {},
   "source": [
    "### Text or LangChain Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297c5e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = pdf_paper.get_chunks(as_langchain_docs=True)\n",
    "# print(len(docs))\n",
    "# print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60efbc6d",
   "metadata": {},
   "source": [
    "## PDF Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b0f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pdf_paper.get_document_tables()\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8be565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for t in tables:    \n",
    "    md = t.to_markdown()\n",
    "    json_df = t.to_dict()\n",
    "    reborn_df = pd.DataFrame(json_df)\n",
    "    display(Markdown(md))\n",
    "    print(json_df)\n",
    "    print(reborn_df.head(10))\n",
    "    print(\"\\n========================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076bc862",
   "metadata": {},
   "source": [
    "## PDF to Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb91a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    markdown_text = DocumentMarkdown(md_path=\"outputs/paper_text.md\").get_markdown()\n",
    "except FileNotFoundError:\n",
    "    markdown_text = pdf_paper.get_markdown()\n",
    "    with open(\"outputs/paper_text.md\", \"w\") as f:\n",
    "        f.write(markdown_text)\n",
    "\n",
    "markdown_paper = DocumentMarkdown(md_content=markdown_text, md_path=\"outputs/paper_text.md\")\n",
    "# display(Markdown(markdown_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd0c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not Satisfactory, will create our own MD Chunker\n",
    "# # pip install langchain-community\n",
    "# # pip install unstructured\n",
    "# # pip install markdown\n",
    "\n",
    "# from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "# loader = UnstructuredMarkdownLoader(\n",
    "#     \"outputs/paper_text.md\",\n",
    "#     mode=\"elements\",\n",
    "#     strategy=\"fast\",\n",
    "# )\n",
    "\n",
    "# docs = loader.load()\n",
    "# for doc in docs:\n",
    "#     print(doc.metadata)\n",
    "#     print(len(doc.page_content))\n",
    "#     print(doc.page_content[:100])  # Print the first 100 characters of the content\n",
    "#     print(doc.page_content[-100:])  # Print the last 100 characters of the content\n",
    "#     print(\"\\n---\\n\")  # Separator for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0599aa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_paper.get_markdown(only_text=True, remove_references=True)[-1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cffc9a",
   "metadata": {},
   "source": [
    "### Get Chunks from Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d49c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: paginate markdown before passing it to the splitter (just pass each page independently) and keep the chunk metadata\n",
    "chunks = markdown_paper.convert_to_chunks(mode=\"chars\",chunk_size=1500, overlap=100)\n",
    "print(len(chunks))\n",
    "with open(\"outputs/paper_chunks.txt\", \"w\") as f:\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        f.write(f\"\\n----- Chunk {i + 1} (Size {len(chunk)} chars) -----\\n{chunk}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cdf62e",
   "metadata": {},
   "source": [
    "### Quick RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install chromadb\n",
    "# pip install sentence-transformers\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "try:\n",
    "    client.delete_collection(name=\"paper_chunks\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"outputs/chroma_db\")\n",
    "paper_collection = client.create_collection(name=\"paper_chunks\")\n",
    "text_embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    embedding = text_embedding_model.encode(chunk)\n",
    "    paper_collection.add(\n",
    "        ids=[f\"chunk_{i + 1}\"],\n",
    "        documents=[chunk],\n",
    "        embeddings=[embedding.tolist()],\n",
    "        metadatas=[{\"chunk_id\": i + 1, \"source\": str(markdown_paper.md_path), \"title\": markdown_paper.get_title()}],\n",
    "        \n",
    "    )\n",
    "    print({\"chunk_id\": i + 1, \"source\": markdown_paper.md_path, \"title\": markdown_paper.get_title()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6754c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, collection, top_k=3):\n",
    "    query_embedding = text_embedding_model.encode(query)\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding.tolist()], n_results=top_k\n",
    "    )\n",
    "    return results\n",
    " \n",
    "# def generate_response(query, context):\n",
    "#     prompt = f\"Query: {query}\\nContext: {context}\\nAnswer:\"\n",
    "#     response = completion(\n",
    "#         model=\"gemini/gemini-1.5-flash\",\n",
    "#         messages=[{\"content\": prompt, \"role\": \"user\"}],\n",
    "#         api_key=gemini_api_key\n",
    "#     )\n",
    "#     return response['choices'][0]['message']['content']\n",
    "\n",
    "# Example usage\n",
    "query = \"Is rotavirus in waterbourne surfaces?\"\n",
    "results = semantic_search(query, paper_collection, top_k=3)\n",
    "for i, doc in enumerate(results['documents'][0]):\n",
    "    print(f\"Result {i + 1}:\")\n",
    "    print(f\"Chunk ID: {results['metadatas'][0][i]['chunk_id']}\")\n",
    "    print(f\"Source: {results['metadatas'][0][i]['source']}\")\n",
    "    print(f\"Title: {results['metadatas'][0][i]['title']}\")\n",
    "    print(f\"Content: {doc}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
