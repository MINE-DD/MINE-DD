{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ecd74b",
   "metadata": {},
   "source": [
    "## Using PaperQA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b992f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from paperqa.readers import parse_pdf_to_pages\n",
    "\n",
    "PAPERS_DIR = Path.home() / \"papers_minedd\"\n",
    "\n",
    "test_paper = PAPERS_DIR / \"Seasonality_of_rotavirus_disease_in_the_tropics_a_systematic_review_and_meta-analysis.pdf\"\n",
    "\n",
    "parsed_text = parse_pdf_to_pages(str(test_paper))\n",
    "parsed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc09b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in parsed_text.content.items():\n",
    "    print(f\"Page {k}:\")\n",
    "    print(v[:100].replace('\\n', ' '))\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e891d2",
   "metadata": {},
   "source": [
    "## Using PyMuPDF Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf890de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf4llm\n",
    "\n",
    "# Table Strategies: https://pymupdf.readthedocs.io/en/latest/page.html#Page.find_tables\n",
    "md_text = pymupdf4llm.to_markdown(test_paper, \n",
    "                                  page_chunks=False, \n",
    "                                  table_strategy=\"lines\", \n",
    "                                  embed_images=False\n",
    "                                  )\n",
    "# Write the text to some file in UTF8-encoding\n",
    "Path(\"output_pymupdf.md\").write_bytes(md_text.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5939f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(md_text), md_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1e8d56",
   "metadata": {},
   "source": [
    "# Extract PDF Tables with GMFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gmft.auto import AutoTableDetector, AutoTableFormatter\n",
    "from gmft.pdf_bindings import PyPDFium2Document\n",
    "\n",
    "def save_tables_in_multiple_formats(tables):\n",
    "    for index, table in enumerate(tables):\n",
    "        table.df().to_csv(f\"output_tables/output_table_{index}.csv\", index=False)\n",
    "        # table.df().to_json(f\"output_tables/output_table_{index}.json\", orient='records')\n",
    "\n",
    "def extract_tables(pdf_path):\n",
    "    detector = AutoTableDetector()\n",
    "    formatter = AutoTableFormatter()\n",
    "    doc = PyPDFium2Document(pdf_path)\n",
    "    tables = []\n",
    "    for page in doc:\n",
    "        tables += detector.extract(page)\n",
    "    formatted_tables = [formatter.extract(table) for table in tables]\n",
    "    return formatted_tables\n",
    "\n",
    "# Extract tables from the PDF\n",
    "tables = extract_tables(test_paper)\n",
    "save_tables_in_multiple_formats(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e3f190",
   "metadata": {},
   "source": [
    "# Use Marker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf8d20",
   "metadata": {},
   "source": [
    "## Full PDF into Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ea662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from marker.converters.pdf import PdfConverter\n",
    "from marker.models import create_model_dict\n",
    "from marker.output import text_from_rendered\n",
    "from marker.config.parser import ConfigParser\n",
    "\n",
    "# Configure Marker to use Ollama as the LLM service\n",
    "config = {\n",
    "    \"output_format\": \"markdown\",\n",
    "    \"use_llm\": True,\n",
    "    \"llm_service\": \"marker.services.ollama.OllamaService\",\n",
    "    \"ollama_model\": \"llama3.2:latest\",  # Specify which model you want to use\n",
    "    \"ollama_base_url\": \"http://localhost:11434\"  # Default Ollama URL\n",
    "}\n",
    "\n",
    "# Create config parser\n",
    "config_parser = ConfigParser(config)\n",
    "\n",
    "# Initialize the PDF converter with Ollama integration\n",
    "converter = PdfConverter(\n",
    "    config=config_parser.generate_config_dict(),\n",
    "    artifact_dict=create_model_dict(),\n",
    "    processor_list=config_parser.get_processors(),\n",
    "    renderer=config_parser.get_renderer(),\n",
    "    llm_service=config_parser.get_llm_service()\n",
    ")\n",
    "\n",
    "# Convert PDF to markdown\n",
    "pdf_path = str(test_paper)\n",
    "rendered = converter(pdf_path)\n",
    "\n",
    "# Extract the markdown text and images\n",
    "text, _, images = text_from_rendered(rendered)\n",
    "\n",
    "# Print or save the markdown\n",
    "print(len(text))\n",
    "\n",
    "# Optionally save to a file\n",
    "with open(\"output_marker.md\", \"w\") as f:\n",
    "    f.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ebe7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76e25da0",
   "metadata": {},
   "source": [
    "# Use MistralAI\n",
    "(Paid API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df5b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Source: https://github.com/amayuelas/corpus-automation/blob/main/parse_pdf_mistral.ipynb\n",
    "import os\n",
    "import argparse\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from mistralai import Mistral\n",
    "from mistralai import DocumentURLChunk\n",
    "import json\n",
    "import time\n",
    "\n",
    "def pdf2markdown(pdf_file: Path, output_dir: Path, client: Mistral):\n",
    "    \"\"\"Process a single PDF file and save results to output directory.\n",
    "    \n",
    "    Args:\n",
    "        pdf_file: Path to the PDF file to process\n",
    "        output_dir: Directory where results will be saved\n",
    "        client: Mistral client instance\n",
    "    \"\"\"\n",
    "    print(f\"Processing {pdf_file} ...\")\n",
    "\n",
    "    # Upload PDF file to Mistral's OCR service\n",
    "    uploaded_file = client.files.upload(\n",
    "        file={\n",
    "            \"file_name\": pdf_file.name,\n",
    "            \"content\": pdf_file.read_bytes(),\n",
    "        },\n",
    "        purpose=\"ocr\",\n",
    "    )\n",
    "\n",
    "    # Get URL for the uploaded file\n",
    "    signed_url = client.files.get_signed_url(file_id=uploaded_file.id, expiry=1)\n",
    "\n",
    "    # Process PDF with OCR, including embedded images\n",
    "    pdf_response = client.ocr.process(\n",
    "        document=DocumentURLChunk(document_url=signed_url.url),\n",
    "        model=\"mistral-ocr-latest\",\n",
    "        include_image_base64=True\n",
    "    )\n",
    "\n",
    "    # Convert response to JSON format\n",
    "    response_dict = json.loads(pdf_response.model_dump_json())\n",
    "\n",
    "    # Save response to JSON file\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    with open(output_dir / \"response.json\", \"w\") as f:\n",
    "        json.dump(response_dict, f)\n",
    "\n",
    "    # Save images to PNG files\n",
    "    images_dir = output_dir / \"mistral_images\"\n",
    "    images_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    for page in pdf_response.pages:\n",
    "        for img in page.images:\n",
    "            # Extract base64 data after the comma\n",
    "            img_data = img.image_base64.split(',')[1]\n",
    "            # Decode and save image\n",
    "            img_bytes = base64.b64decode(img_data)\n",
    "            with open(images_dir / img.id, \"wb\") as f:\n",
    "                f.write(img_bytes)\n",
    "            \n",
    "    # Save raw text\n",
    "    with open(output_dir / \"text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for page in pdf_response.pages:\n",
    "            f.write(page.markdown)  # Use markdown instead of text attribute\n",
    "    \n",
    "    return pdf_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4235a312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import ImageURLChunk, TextChunk\n",
    "def extract_page_struct(image_ocr_markdown: str, page_index: int, output_dir: Path, client: Mistral):\n",
    "    # Get structured response from model\n",
    "    chat_response = client.chat.complete(\n",
    "    model=\"mistral-large-latest\", #\"ministral-8b-latest\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                TextChunk(\n",
    "                    text=(\n",
    "                        f\"This is image's OCR in markdown:\\n\\n{image_ocr_markdown}\\n.\\n\"\n",
    "                        \"Convert this into a sensible structured json response. \"\n",
    "                        \"Pay special attention to table content\"\n",
    "                        \"The output should be strictly be json with no extra commentary\"\n",
    "                    )\n",
    "                ),\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    temperature=0,\n",
    "    )\n",
    "\n",
    "    # Parse and return JSON response\n",
    "    try:\n",
    "        response_dict = json.loads(chat_response.choices[0].message.content)\n",
    "        with open(output_dir / f\"response_page_{page_index}.json\", \"w\") as f:\n",
    "            json.dump(response_dict, f, indent=4)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for page {page_index}: {e}\")\n",
    "        response_dict = {}\n",
    "    return response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987cd016",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_MISTRAL_OCR = False\n",
    "\n",
    "pdf_response = None\n",
    "output_dir = Path('mistral_ocr/')\n",
    "\n",
    "if RUN_MISTRAL_OCR:\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv(override=True)\n",
    "    mistral_api_key = os.getenv('MISTRAL_API_KEY')\n",
    "\n",
    "    if not mistral_api_key:\n",
    "        raise ValueError(\"Please set the MISTRAL_API_KEY environment variable.\")\n",
    "    else:\n",
    "        client = Mistral(api_key=mistral_api_key)\n",
    "        pdf_response = pdf2markdown(test_paper, output_dir, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225288c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai.models import OCRResponse\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def replace_images_in_markdown(markdown_str: str, images_dict: dict) -> str:\n",
    "    \"\"\"\n",
    "    Replace image placeholders in markdown with base64-encoded images.\n",
    "\n",
    "    Args:\n",
    "        markdown_str: Markdown text containing image placeholders\n",
    "        images_dict: Dictionary mapping image IDs to base64 strings\n",
    "\n",
    "    Returns:\n",
    "        Markdown text with images replaced by base64 data\n",
    "    \"\"\"\n",
    "    for img_name, base64_str in images_dict.items():\n",
    "        markdown_str = markdown_str.replace(\n",
    "            f\"![{img_name}]({img_name})\", f\"![{img_name}]({base64_str})\"\n",
    "        )\n",
    "    return markdown_str\n",
    "\n",
    "def get_combined_markdown(ocr_response: OCRResponse) -> list[str]:\n",
    "    \"\"\"\n",
    "    Combine OCR text and images into a single markdown document.\n",
    "\n",
    "    Args:\n",
    "        ocr_response: Response from OCR processing containing text and images\n",
    "\n",
    "    Returns:\n",
    "        Combined markdown string with embedded images\n",
    "    \"\"\"\n",
    "    markdowns: list[str] = []\n",
    "    # Extract images from page\n",
    "    for page in ocr_response.pages:\n",
    "        image_data = {}\n",
    "        for img in page.images:\n",
    "            image_data[img.id] = img.image_base64\n",
    "        # Replace image placeholders with actual images\n",
    "        enriched_markdown = replace_images_in_markdown(page.markdown, image_data)\n",
    "        markdowns.append(enriched_markdown)\n",
    "\n",
    "    return markdowns\n",
    "\n",
    "# Display combined markdowns and images\n",
    "if pdf_response:\n",
    "    markdowns = get_combined_markdown(pdf_response)\n",
    "    makrdown_str = \"\\n\\n\".join(markdowns)\n",
    "    display(Markdown(makrdown_str))\n",
    "else:\n",
    "    markdowns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bff6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate the pages (NOT the markdowns!!) because those have the images as binary strings only, so it is useless\n",
    "if pdf_response:\n",
    "    for i, page in enumerate(pdf_response.pages):\n",
    "        print(f\"Processing page {i} ...\")\n",
    "        extract_page_struct(page.markdown, i, output_dir, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5440c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_json = json.loads((output_dir / \"response.json\").read_text())\n",
    "[print(x.keys()) for x in mistral_json['pages']]\n",
    "print(len(mistral_json['pages']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3e8ca9",
   "metadata": {},
   "source": [
    "# Use LLM to Extract Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd687798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# This is a simple example of using the OllamaLLM with a prompt template.\n",
    "template = \"\"\"Here is a paragraph with some information : {text_chunk}\n",
    "This paragraph has one or more claims inside it. Provide me with a list of the claims in the paragraph.\n",
    "The response should only be one claim per line, no other text.\n",
    "Each claim should be a precise sentence pointing to a fact. \n",
    "Stick as much as possible to the literal text.\n",
    "Do not infer claims that are not explicitly stated in the text.\n",
    "Each claim in the list should be separated by a new line and not contain any other text or number.\n",
    "\n",
    "Claims: \n",
    "\n",
    "\"\"\"    \n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = OllamaLLM(model=\"llama3.2:latest\")\n",
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paragraphs(text):\n",
    "    \"\"\"\n",
    "    Splits the text into paragraphs based on newlines.\n",
    "    \"\"\"\n",
    "    paragraphs = []\n",
    "    for p in text.split('\\n'):\n",
    "        if len(p) > 1 and not p.startswith(\"Question\"):\n",
    "            if p.startswith(\"References\"):\n",
    "                break\n",
    "            paragraphs.append(p)\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "example_paperQA_output = \"\"\"\n",
    "Question: How does the seasonality of rotavirus differ between tropical and temperate climates?\n",
    "\n",
    "The seasonality of rotavirus differs between tropical and temperate climates. In temperate zones, rotavirus is more common in cooler months, with a strong winter peak observed primarily in the Americas (Seasonality of Rotavirus in South Asia_ A Meta-Analysis Approach Assessing Associations with Temperature_ Precipitation_ and Vegetation Index.pdf pages 1-2). However, in tropical regions, the pattern is less defined, and autumn/spring peaks are more common.\n",
    "\n",
    "In tropical climates, rotavirus incidence responds to changes in climate, with the highest number of infections found at the colder and drier times of the year (levy2009seasonalityofrotavirus pages 1-1). Monthly rotavirus incidence is significantly negatively correlated with temperature, rainfall, and relative humidity in the majority of studies reviewed (levy2009seasonalityofrotavirus pages 8-8).\n",
    "\n",
    "In contrast to temperate areas, where rotavirus incidence often goes to zero in some months, tropical regions experience year-round rotavirus activity with peaks and valleys (levy2009seasonalityofrotavirus pages 6-6). The effect of seasonal changes on rotavirus incidence is not as extreme in the tropics as it is in temperate areas. Less climatic variability exists in tropical climates, which may explain why variations in climatological variables are not large enough to cause the observed effect (levy2009seasonalityofrotavirus pages 6-6).\n",
    "\n",
    "Overall, the seasonality of rotavirus disease in tropical countries differs from that observed in temperate zones, with tropical regions experiencing year-round activity and responding to changes in climate (levy2009seasonalityofrotavirus pages 8-8).\n",
    "\n",
    "References\n",
    "\n",
    "1. (Seasonality of Rotavirus in South Asia_ A Meta-Analysis Approach Assessing Associations with Temperature_ Precipitation_ and Vegetation Index.pdf pages 1-2): Jagai, Jyotsna S., et al. \"Seasonality of Rotavirus in South Asia: A Meta-Analysis Approach Assessing Associations with Temperature, Precipitation, and Vegetation Index.\" PLoS ONE, vol. 7, no. 5, 2012, doi:10.1371/journal.pone.0038168.\n",
    "\n",
    "2. (levy2009seasonalityofrotavirus pages 1-1): K. Levy, A. E Hubbard, and J. N. Eisenberg. Seasonality of rotavirus disease in the tropics: a systematic review and meta-analysis. International journal of epidemiology, 38 6:1487-96, Dec 2009. URL: https://doi.org/10.1093/ije/dyn260, doi:10.1093/ije/dyn260. This article has 265 citations and is from a highest quality peer-reviewed journal.\n",
    "\n",
    "3. (levy2009seasonalityofrotavirus pages 6-6): K. Levy, A. E Hubbard, and J. N. Eisenberg. Seasonality of rotavirus disease in the tropics: a systematic review and meta-analysis. International journal of epidemiology, 38 6:1487-96, Dec 2009. URL: https://doi.org/10.1093/ije/dyn260, doi:10.1093/ije/dyn260. This article has 265 citations and is from a highest quality peer-reviewed journal.\n",
    "\n",
    "4. (levy2009seasonalityofrotavirus pages 8-8): K. Levy, A. E Hubbard, and J. N. Eisenberg. Seasonality of rotavirus disease in the tropics: a systematic review and meta-analysis. International journal of epidemiology, 38 6:1487-96, Dec 2009. URL: https://doi.org/10.1093/ije/dyn260, doi:10.1093/ije/dyn260. This article has 265 citations and is from a highest quality peer-reviewed journal.\n",
    "\n",
    "\"\"\"\n",
    "text_chunks = get_paragraphs(example_paperQA_output)\n",
    "assert len(text_chunks) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4443cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = []\n",
    "for text in text_chunks:\n",
    "    claims.append(chain.invoke({\"text_chunk\": text}))\n",
    "claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e55bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_claim(claim_str):\n",
    "    \"\"\"\n",
    "    Formats the claims into a list.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        claims = claim_str.split(\"\\n\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error splitting claims: {e}\")\n",
    "        return []\n",
    "    return claims\n",
    "    \n",
    "\n",
    "claim_list = [format_claim(claim) for claim in claims]\n",
    "for chunk, claims in zip(text_chunks, claim_list):\n",
    "    print(f\"Text: {chunk}\\n\")\n",
    "    [print(c) for c in claims]\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5c71e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "paper_claims = {}\n",
    "\n",
    "OBTAIN_PDF_CLAIMS = False\n",
    "\n",
    "if OBTAIN_PDF_CLAIMS:\n",
    "    for page_number, page_content in parsed_text.content.items():\n",
    "        page_paragraphs = get_paragraphs(page_content)\n",
    "        print(f\"----- Found {len(page_paragraphs)} paragraphs in page {page_number} -----\")\n",
    "        for pi, paragraph in enumerate(page_paragraphs):\n",
    "            if len(paragraph.split()) < 10:\n",
    "                claim_list = []\n",
    "            else:\n",
    "                claims = chain.invoke({\"text_chunk\": paragraph})\n",
    "                claim_list = format_claim(claims)\n",
    "            print(f\"Page {page_number} - Paragraph {pi} has {len(claim_list)} claims\")\n",
    "            paper_claims[f\"{page_number}_{pi}\"] = {\"text\": paragraph[:500], \"claims\": claim_list}\n",
    "\n",
    "    # Save the claims to a JSON file\n",
    "    with open(\"paper_claims.json\", \"w\") as f:\n",
    "        json.dump(paper_claims, f, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
